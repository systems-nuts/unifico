Swarztrauber() /home/nikos/phd/unified_abi/layout/npb/ft/ft_aarch64_aligned.out
Event: cycles

Percent        
               
               
        3    Disassembly of section .text:
               
        5    0000000000502860 <Swarztrauber>:
        6    Swarztrauber():
        59   // Swarztrauber to
        60   // perform FFTs
        61   //---------------------------------------------------------------------
        62   static void Swarztrauber(int is, int m, int vlen, int n, int xd1, void *ox,
        63   dcomplex exponent[n])
        64   {          
  0.00         sub   sp, sp, #0xc0
               stp   x20, x19, [sp, #160]
               stp   x29, x30, [sp, #176]
               add   x29, sp, #0xb0
               
        67   int i, j, l;
        68   dcomplex u1, x11, x21;
        69   int k, n1, li, lj, lk, ku, i11, i12, i21, i22;
               
        71   if (timers_enabled)
               adrp  x8, __libc
  0.00         ldr   x6, [x29, #16]
               ldr   w8, [x8, #136]
               mov   w20, w2  
        60   dcomplex(*x)[xd1] = (dcomplex(*)[xd1])ox;
               mov   w19, w4  
  0.00         str   w3, [sp, #16]
  0.00         str   w1, [sp, #32]
               str   x5, [sp, #8]
  0.00         str   w0, [sp, #84]
        66   if (timers_enabled)
             ↓ cbz   w8, 50   
        67   timer_start(4);
               mov   w0, #0x4                        // #4
               nop            
             → bl    timer_start
               ldr   x6, [x29, #16]
               ldr   w0, [sp, #84]
               ldr   x5, [sp, #8]
         50:   ldr   w8, [sp, #16]
               ldr   w3, [sp, #32]
        71   //---------------------------------------------------------------------
        72   // Perform one variant of the Stockham FFT.
        73   //---------------------------------------------------------------------
        74   n1 = n / 2;
               cmp   w8, #0x0 
               cinc  w8, w8, lt  // lt = tstop
        74   lj = 1;    
        75   li = 1 << m;
        76   for (l = 1; l <= m; l += 2) {
               cmp   w3, #0x1 
             ↓ b.lt  504      
               asr   w8, w8, #1
               str   w8, [sp, #20]
               ldr   w8, [sp, #32]
               mov   w7, #0x1                        // #1
               mov   w30, #0x1                       // #1
        73   li = 1 << m;
  0.00         lsl   w2, w7, w8
               mov   w8, w20  
               stur  x8, [x29, #-32]
               ldr   w8, [sp, #16]
               mov   w8, w8   
               str   x8, [sp] 
        74   for (l = 1; l <= m; l += 2) {
               add   x8, x5, #0x8
               stur  x8, [x29, #-40]
        80   lk = lj;   
        81   lj = 2 * lk;
        82   li = li / 2;
        83   ku = li;   
               
        85   for (i = 0; i <= li - 1; i++) {
               lsl   x8, x19, #4
             ↓ b     c8       
  0.00   a4:   ldr   x3, [sp, #40]
  0.00         mov   w19, w3  
  0.00   ac:   ldr   w2, [sp, #32]
        74   for (l = 1; l <= m; l += 2) {
  0.00         add   w7, w7, #0x2
  0.00         mov   w3, w7   
               mov   w30, w19 
  0.00         subs  w3, w3, w2
               mov   w2, w16  
             ↓ b.gt  504      
        76   lj = 2 * lk;
  0.00   c8:   lsl   w3, w30, #1
        77   li = li / 2;
               cmp   w2, #0x0 
               str   x3, [sp, #40]
               cinc  w3, w2, lt  // lt = tstop
  0.00         asr   w16, w3, #1
        80   for (i = 0; i <= li - 1; i++) {
               cmp   w2, #0x2 
               str   w7, [sp, #36]
  0.00         str   w2, [sp, #24]
  0.00         stur  x30, [x29, #-80]
  0.00       ↓ b.lt  2a0      
               sxtw  x3, w16  
  0.00         str   x3, [sp, #72]
  0.00         ldr   x3, [sp, #40]
               mov   w4, w30  
               mov   x18, xzr 
  0.00         str   x16, [sp, #88]
               sxtw  x2, w3   
               sxtw  x3, w30  
               mul   x3, x3, x8
               str   x3, [sp, #56]
               lsl   w3, w30, #1
               str   w3, [sp, #52]
  0.00         mov   w3, #0x210                      // #528
  0.00         mul   x2, x2, x3
  0.00         adrp  x3, plane+0x41ea0
  0.00         add   x3, x3, #0x168
  0.00         stur  x3, [x29, #-48]
  0.00         ldr   w3, [sp, #20]
               str   x2, [sp, #64]
  0.00         stp   w30, w3, [x29, #-60]
               mov   w3, w30  
               ldur  x3, [x29, #-40]
  0.00         stur  x3, [x29, #-72]
             ↓ b     1a4      
  0.04  150:   ldr   x3, [sp, #56]
  0.02         ldp   x30, x2, [x29, #-80]
  0.03         ldr   x16, [sp, #88]
  0.03         ldr   w0, [sp, #84]
  0.01         ldr   x6, [x29, #16]
  0.01         add   x2, x2, x3
  0.00         stur  x2, [x29, #-72]
  0.02         ldr   w3, [sp, #52]
  0.02         ldur  w2, [x29, #-60]
  0.01         add   x18, x18, #0x1
  0.01         add   w2, w2, w3
  0.02         ldur  w3, [x29, #-56]
  0.01         add   w3, w3, w30
  0.01         stp   w2, w3, [x29, #-60]
  0.00         ldr   x3, [sp, #64]
  0.02         ldur  x2, [x29, #-48]
  0.01         add   x2, x2, x3
  0.02         mov   x3, x18  
  0.00         subs  x3, x3, x16
  0.02         stur  x2, [x29, #-48]
  0.01       ↓ b.eq  2a0      
  0.01  1a4:   ldr   x3, [sp, #72]
        86   i11 = i * lk;
        87   i12 = i11 + n1;
        88   i21 = i * lj;
        89   i22 = i21 + lk;
               
        91   if (is >= 1) {
  0.01         cmp   w0, #0x0 
  0.02         add   x3, x18, x3
  0.01         add   x3, x6, x3, lsl #4
  0.01         ldr   d0, [x3, #8]
  0.19         fneg  d1, d0   
  0.09         fcsel d0, d0, d1, gt
        92   u1 = exponent[ku + i];
        93   }          
        94   else {     
        95   u1 = dconjg(exponent[ku + i]);
        96   }          
        97   for (k = 0; k <= lk - 1; k++) {
  0.00         cmp   w30, #0x1
             ↑ b.lt  150      
  0.00         ldr   d1, [x3] 
  0.01         ldur  x7, [x29, #-48]
  0.02         ldp   w1, w30, [x29, #-60]
  0.01         ldur  x5, [x29, #-72]
  0.01         mov   x3, xzr  
        93   for (j = 0; j < vlen; j++) {
  0.02         cmp   w20, #0x1
  0.00       ↓ b.ge  20c      
        92   for (k = 0; k <= lk - 1; k++) {
  0.02  1e4:   add   x3, x3, #0x1
  0.01         mov   x2, x3   
  0.02         add   x5, x5, x8
  0.07         add   w1, w1, #0x1
  0.02         add   w30, w30, #0x1
  0.01         add   x7, x7, #0x210
  0.01         subs  x2, x2, x4
             ↑ b.eq  150      
        93   for (j = 0; j < vlen; j++) {
  0.06         cmp   w20, #0x1
             ↑ b.lt  1e4      
  0.01  20c:   adrp  x19, plane+0x41ea0
  0.02         sxtw  x2, w1   
  0.04         mov   w0, #0x210                      // #528
  0.05         add   x19, x19, #0x160
  0.04         madd  x0, x0, x2, x19
  0.06         ldur  x2, [x29, #-40]
  0.04         sxtw  x16, w30 
  0.03         add   x17, x0, #0x8
  0.02         mov   x6, x7   
  0.12         madd  x16, x16, x8, x2
  0.07         ldur  x2, [x29, #-32]
  0.02         mov   x19, x5  
        94   x11 = x[i11 + k][j];
  1.87  23c:   ldp   d2, d3, [x19, #-8]
        95   x21 = x[i12 + k][j];
  4.28         ldp   d4, d5, [x16, #-8]
        93   for (j = 0; j < vlen; j++) {
  8.74         subs  x2, x2, #0x1
  1.42         add   x19, x19, #0x10
        96   scr[i21 + k][j] = dcmplx_add(x11, x21);
  5.86         mov   v6.16b, v2.16b
  0.91         mov   v7.16b, v3.16b
  6.12         fadd  d6, d6, d4
  0.93         fadd  d7, d7, d5
        97   scr[i22 + k][j] = dcmplx_mul(u1, dcmplx_sub(x11, x21));
  0.31         fsub  d2, d2, d4
  0.22         mov   v4.16b, v1.16b
  1.99         fsub  d3, d3, d5
  0.41         mov   v5.16b, v0.16b
  1.80         fmul  d4, d4, d2
  1.03         fmul  d5, d5, d3
  1.39         fmul  d3, d3, d1
  0.41         fmul  d2, d2, d0
  5.51         fsub  d4, d4, d5
  0.38         fadd  d2, d2, d3
        96   scr[i21 + k][j] = dcmplx_add(x11, x21);
  0.73         stp   d6, d7, [x6, #-8]
        97   scr[i22 + k][j] = dcmplx_mul(u1, dcmplx_sub(x11, x21));
  0.50         stp   d4, d2, [x17, #-8]
        93   for (j = 0; j < vlen; j++) {
  7.41         add   x17, x17, #0x10
  0.22         add   x16, x16, #0x10
  1.27         add   x6, x6, #0x10
             ↑ b.ne  23c      
  0.14       ↑ b     1e4      
  0.01  2a0:   ldp   w2, w7, [sp, #32]
        102  }          
        103  }          
        104  }          
               
        106  if (l == m) {
  0.00         mov   w3, w7   
               subs  w3, w3, w2
             ↓ b.ne  314      
  0.00         ldr   w3, [sp, #16]
        103  for (k = 0; k < n; k++) {
               cmp   w3, #0x1 
             ↑ b.lt  a4       
               ldp   x5, x30, [sp]
               adrp  x4, plane+0x41ea0
               add   x4, x4, #0x160
               mov   x1, xzr  
        104  for (j = 0; j < vlen; j++) {
               cmp   w20, #0x1
             ↓ b.ge  2f4      
        103  for (k = 0; k < n; k++) {
  0.03  2d4:   add   x1, x1, #0x1
  0.00         mov   x3, x1   
  0.01         add   x4, x4, #0x210
  0.00         add   x30, x30, x8
  0.01         subs  x3, x3, x5
             ↑ b.eq  a4       
        104  for (j = 0; j < vlen; j++) {
  0.00         cmp   w20, #0x1
  0.01       ↑ b.lt  2d4      
  0.00  2f4:   ldur  x19, [x29, #-32]
  0.01         mov   x2, x30  
  0.00         mov   x3, x4   
        105  x[k][j] = scr[k][j];
  0.11  300:   ldr   q0, [x3], #16
        104  for (j = 0; j < vlen; j++) {
  0.42         subs  x19, x19, #0x1
        105  x[k][j] = scr[k][j];
  0.66         str   q0, [x2], #16
        104  for (j = 0; j < vlen; j++) {
  0.20       ↑ b.ne  300      
  0.00       ↑ b     2d4      
  0.00  314:   ldr   w2, [sp, #24]
        111  }          
        112  }          
        113  }          
        114  else {     
        115  lk = lj;   
        116  lj = 2 * lk;
               lsl   w19, w30, #2
        112  li = li / 2;
  0.00         add   w3, w2, #0x3
  0.00         cmp   w2, #0x0 
               csel  w3, w3, w2, lt  // lt = tstop
               asr   w16, w3, #2
        115  ku = li;   
               
        117  for (i = 0; i <= li - 1; i++) {
               cmp   w2, #0x4 
             ↑ b.lt  ac       
  0.00         sxtw  x2, w19  
               mul   x2, x2, x8
  0.00         str   x2, [sp, #64]
  0.00         adrp  x2, plane+0x41ea0
               add   x2, x2, #0x168
               ldr   x3, [sp, #40]
               stur  x2, [x29, #-48]
               ldur  x2, [x29, #-40]
               str   x19, [sp, #24]
  0.00         sxtw  x1, w3   
  0.00         sxtw  x3, w16  
  0.00         stur  x2, [x29, #-56]
               ldr   w2, [sp, #20]
  0.00         str   x3, [sp, #72]
               add   x3, x1, x1, lsl #5
               lsl   x3, x3, #4
               str   x3, [sp, #56]
  0.00         lsl   w3, w30, #1
               lsl   w19, w30, #2
               mov   x4, xzr  
  0.00         str   w19, [sp, #40]
               stur  w2, [x29, #-60]
  0.00         str   w3, [sp, #52]
  0.00         stur  w3, [x29, #-72]
  0.00         str   x16, [sp, #88]
             ↓ b     3fc      
  0.05  39c:   ldr   x3, [sp, #56]
  0.00         ldur  x2, [x29, #-48]
  0.01         ldr   x16, [sp, #88]
  0.01         ldr   w0, [sp, #84]
  0.01         ldr   x6, [x29, #16]
  0.01         add   x2, x2, x3
  0.01         stur  x2, [x29, #-48]
  0.01         ldr   w3, [sp, #40]
  0.01         ldur  w2, [x29, #-72]
  0.00         ldur  x30, [x29, #-80]
  0.00         add   x4, x4, #0x1
  0.02         add   w2, w2, w3
  0.00         stur  w2, [x29, #-72]
  0.00         ldr   w3, [sp, #52]
  0.00         ldur  w2, [x29, #-60]
  0.01         add   w2, w2, w3
  0.00         stur  w2, [x29, #-60]
  0.00         ldr   x3, [sp, #64]
  0.00         ldur  x2, [x29, #-56]
  0.01         add   x2, x2, x3
  0.01         mov   x3, x4   
  0.00         subs  x3, x3, x16
  0.00         stur  x2, [x29, #-56]
  0.01       ↓ b.eq  4f8      
  0.00  3fc:   ldr   x3, [sp, #72]
        121  i11 = i * lk;
        122  i12 = i11 + n1;
        123  i21 = i * lj;
        124  i22 = i21 + lk;
               
        126  if (is >= 1) {
  0.00         cmp   w0, #0x0 
  0.00         add   x3, x4, x3
  0.01         add   x3, x6, x3, lsl #4
  0.01         ldr   d0, [x3, #8]
  0.10         fneg  d1, d0   
  0.04         fcsel d0, d0, d1, gt
        127  u1 = exponent[ku + i];
        128  }          
        129  else {     
        130  u1 = dconjg(exponent[ku + i]);
        131  }          
        132  for (k = 0; k <= lk - 1; k++) {
  0.00         cmp   w30, #0x1
             ↑ b.lt  39c      
  0.00         ldr   d1, [x3] 
  0.00         ldp   x5, x6, [x29, #-56]
  0.02         ldur  w16, [x29, #-60]
  0.00         ldur  w18, [x29, #-72]
  0.00         mov   x3, xzr  
        128  for (j = 0; j < vlen; j++) {
  0.01         cmp   w20, #0x1
             ↓ b.ge  464      
        127  for (k = 0; k <= lk - 1; k++) {
  0.01  43c:   add   x3, x3, #0x1
  0.02         mov   x2, x3   
  0.07         add   x6, x6, #0x210
  0.02         add   w18, w18, #0x1
  0.01         add   w16, w16, #0x1
  0.02         add   x5, x5, x8
  0.07         subs  x2, x2, x1
             ↑ b.ge  39c      
        128  for (j = 0; j < vlen; j++) {
  0.02         cmp   w20, #0x1
  0.01       ↑ b.lt  43c      
  0.01  464:   ldur  x2, [x29, #-40]
  0.05         sxtw  x7, w18  
  0.02         adrp  x30, plane+0x41ea0
  0.02         mov   w0, #0x210                      // #528
  0.05         madd  x7, x7, x8, x2
  0.07         sxtw  x2, w16  
  0.02         add   x30, x30, #0x160
  0.05         madd  x0, x0, x2, x30
  0.07         ldur  x2, [x29, #-32]
  0.03         add   x17, x0, #0x8
  0.01         mov   x19, x5  
  0.04         mov   x30, x6  
        129  x11 = scr[i11 + k][j];
  0.42  494:   ldp   d2, d3, [x30, #-8]
        130  x21 = scr[i12 + k][j];
  0.85         ldp   d4, d5, [x17, #-8]
        128  for (j = 0; j < vlen; j++) {
  4.64         subs  x2, x2, #0x1
  0.46         add   x30, x30, #0x10
        131  x[i21 + k][j] = dcmplx_add(x11, x21);
  4.32         mov   v6.16b, v2.16b
  2.36         mov   v7.16b, v3.16b
  4.23         fadd  d6, d6, d4
  0.99         fadd  d7, d7, d5
        132  x[i22 + k][j] = dcmplx_mul(u1, dcmplx_sub(x11, x21));
  0.28         fsub  d2, d2, d4
  0.98         mov   v4.16b, v1.16b
  1.14         fsub  d3, d3, d5
  0.27         mov   v5.16b, v0.16b
  1.51         fmul  d4, d4, d2
  1.97         fmul  d5, d5, d3
  0.72         fmul  d3, d3, d1
  0.12         fmul  d2, d2, d0
  5.63         fsub  d4, d4, d5
  0.62         fadd  d2, d2, d3
        131  x[i21 + k][j] = dcmplx_add(x11, x21);
  0.23         stp   d6, d7, [x19, #-8]
        132  x[i22 + k][j] = dcmplx_mul(u1, dcmplx_sub(x11, x21));
  0.39         stp   d4, d2, [x7, #-8]
        128  for (j = 0; j < vlen; j++) {
  6.68         add   x7, x7, #0x10
  0.15         add   x17, x17, #0x10
  1.56         add   x19, x19, #0x10
  1.59       ↑ b.ne  494      
  0.02       ↑ b     43c      
  0.00  4f8:   ldr   w7, [sp, #36]
               ldr   x19, [sp, #24]
             ↑ b     ac       
        138  }          
        139  }          
        140  }          
        141  }          
        142  }          
        143  if (timers_enabled)
  0.00  504:   adrp  x8, __libc
               ldr   w8, [x8, #136]
  0.01       ↓ cbz   w8, 550  
        139  timer_stop(4);
               mov   w0, #0x4                        // #4
               nop            
               nop            
               nop            
               nop            
               nop            
               nop            
               nop            
               nop            
               nop            
               nop            
               nop            
               nop            
               nop            
               nop            
             → bl    timer_stop
        140  }          
        550:   ldp   x29, x30, [sp, #176]
               ldp   x20, x19, [sp, #160]
  0.00         add   sp, sp, #0xc0
             ← ret            
